{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLgiaHcfxkWH"
      },
      "source": [
        "# Text Classification Lab\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HassanAlgoz/B5/blob/main/W5_NLP/M3/labs/01_Text_Classification.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook explores three different approaches to text classification using pre-trained models:\n",
        "1. **Task-specific models**: Using models fine-tuned for sentiment analysis\n",
        "2. **Embedding models + Classifier**: Using general-purpose embeddings with a trained classifier\n",
        "3. **Embedding models + Cosine Similarity**: Zero-shot classification without labeled data\n",
        "\n",
        "We'll work with the Rotten Tomatoes movie review dataset to classify reviews as positive or negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57yEB4v48OnJ",
        "outputId": "49aa3223-5830-44bb-8005-1ed89413bb8d"
      },
      "source": [
        "## Getting Started: Loading the Dataset\n",
        "\n",
        "Let's start by loading the Rotten Tomatoes dataset. This dataset contains movie reviews labeled as positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_iGDZCn8RV8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset(\"rotten_tomatoes\")\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwg-HSm9xkWK"
      },
      "source": [
        "### Investigate: Explore the Dataset\n",
        "\n",
        "**Exercise**: Before running the code below, predict what you think the structure of the data will be:\n",
        "- What keys will be in each example?\n",
        "- What will the labels look like (what values will they have)?\n",
        "- How many examples are in train vs test?\n",
        "\n",
        "Now let's examine the data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BN47a198SRG"
      },
      "source": [
        "---\n",
        "\n",
        "## Section A: Using a Task-specific Model\n",
        "\n",
        "### Introduction to Hugging Face Transformers and Pipelines\n",
        "\n",
        "Before we dive into classification, let's get familiar with **Hugging Face Transformers** - one of the most popular libraries for working with pre-trained language models.\n",
        "\n",
        "#### What is Hugging Face Transformers?\n",
        "\n",
        "**Hugging Face Transformers** is a Python library that provides easy access to thousands of pre-trained models for Natural Language Processing (NLP). These models have been trained on massive amounts of text data and can understand language patterns, making them incredibly powerful for various tasks like:\n",
        "- Text classification (sentiment analysis, spam detection, etc.)\n",
        "- Question answering\n",
        "- Text generation\n",
        "- Translation\n",
        "- And much more!\n",
        "\n",
        "#### What is a Pipeline?\n",
        "\n",
        "A **pipeline** is Hugging Face's high-level API that makes it incredibly easy to use pre-trained models. Think of it as a \"one-stop shop\" that handles all the complex steps for you:\n",
        "\n",
        "1. **Loading the model**: Downloads and loads the pre-trained model\n",
        "2. **Tokenization**: Converts text into numbers the model can understand\n",
        "3. **Inference**: Runs the model to make predictions\n",
        "4. **Post-processing**: Formats the output in a readable way\n",
        "\n",
        "**Why use pipelines?**\n",
        "- **Simplicity**: You can classify text in just a few lines of code\n",
        "- **No deep learning knowledge required**: The pipeline handles all the technical details\n",
        "- **Consistent interface**: Same API for different models and tasks\n",
        "- **Production-ready**: Optimized for real-world use\n",
        "\n",
        "#### A Simple Example\n",
        "\n",
        "Here's what using a pipeline looks like (we'll see this in action soon):\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create a sentiment analysis pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Use it!\n",
        "result = classifier(\"I love this movie!\")\n",
        "print(result)\n",
        "# Output: [{'label': 'POSITIVE', 'score': 0.9998}]\n",
        "```\n",
        "\n",
        "That's it! No model architecture knowledge, no tokenization code, no manual inference - just simple, powerful text classification.\n",
        "\n",
        "Now let's use this powerful tool to classify our movie reviews!"
      ]
    },
<<<<<<< HEAD
    "id": "MFnwiq968Xi_",
    "outputId": "7203d25d-edf1-496d-bf37-24db39ede6ef"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    \"\"\"Create and print the classification report\"\"\"\n",
    "    performance = classification_report(\n",
    "        y_true, y_pred,\n",
    "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
    "    )\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Phase\n",
    "\n",
    "**Exercise 1**: Test the pipeline on a single example. What does the output structure look like?\n",
    "```python\n",
    "# Try this:\n",
    "test_text = \"This movie is absolutely fantastic!\"\n",
    "result = pipe(test_text)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Exercise 2**: What are the different scores returned? What do they represent?\n",
    "- Try running the pipeline on different texts (positive, negative, neutral)\n",
    "- What do the scores tell you about the model's confidence?\n",
    "\n",
    "**Exercise 3**: Why do we use `KeyDataset`? What would happen if we passed the data directly?\n",
    "- `KeyDataset` is a helper that extracts the \"text\" field from each example\n",
    "- It makes the pipeline work seamlessly with Hugging Face datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: To improve the performance of our selected model, we could do a few different things including selecting a model trained on our domain data, movie reviews in this case, like DistilBERT base uncased finetuned SST-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojwsml108ZIA"
   },
   "source": [
    "To improve the performance of our selected model, we could do a few different things including selecting a model trained on our domain data, movie reviews in this case, like DistilBERT base uncased finetuned SST-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRIve2Nj8bDD"
   },
   "source": [
    "---\n",
    "\n",
    "## Section B: Using an Embedding Model + Classifier Head\n",
    "\n",
    "### Introduction to Sentence Transformers\n",
    "\n",
    "However, what if we cannot find a model that was pretrained for this specific task? Do we need to fine-tune a representation model ourselves? The answer is no!\n",
    "\n",
    "There might be times when you want to fine-tune the model yourself if you have sufficient computing available. However, not everyone has access to extensive computing. This is where general-purpose embedding models come in.\n",
    "\n",
    "#### What is Sentence Transformers?\n",
    "\n",
    "**Sentence Transformers** is a Python library built on top of Hugging Face Transformers that specializes in creating **embeddings** - numerical representations of text that capture semantic meaning.\n",
    "\n",
    "#### What are Embeddings?\n",
    "\n",
    "Think of embeddings as a way to convert text into a list of numbers (a vector) that captures the **meaning** of the text. For example:\n",
    "- Similar texts get similar numbers (vectors close together)\n",
    "- Different texts get different numbers (vectors far apart)\n",
    "- The numbers capture semantic relationships (e.g., \"king\" and \"queen\" are closer than \"king\" and \"car\")\n",
    "\n",
    "**Why are embeddings useful?**\n",
    "- **Universal representation**: Any text can be converted to the same format (a vector of numbers)\n",
    "- **Semantic understanding**: The numbers capture meaning, not just words\n",
    "- **Flexibility**: You can use embeddings for many different tasks (classification, search, clustering, etc.)\n",
    "- **Efficiency**: Once you have embeddings, you can use simple, fast classifiers on top\n",
    "\n",
    "#### How Sentence Transformers Works\n",
    "\n",
    "1. **Input**: Your text (e.g., \"This movie is fantastic!\")\n",
    "2. **Processing**: The model converts it to a vector of numbers (e.g., 768 numbers)\n",
    "3. **Output**: A dense vector that represents the semantic meaning\n",
    "\n",
    "The model `sentence-transformers/all-mpnet-base-v2` we'll use:\n",
    "- Maps sentences & paragraphs to a **768-dimensional** dense vector space\n",
    "- Each dimension captures some aspect of the text's meaning\n",
    "- Can be used for tasks like clustering, semantic search, or (as we'll see) classification\n",
    "\n",
    "#### The Strategy: Embeddings + Classifier\n",
    "\n",
    "Instead of using a task-specific model, we'll:\n",
    "1. **Convert text to embeddings** using Sentence Transformers (frozen, no training needed)\n",
    "2. **Train a simple classifier** (like Logistic Regression) on top of these embeddings\n",
    "\n",
    "This approach gives us:\n",
    "- ✅ Flexibility to adapt to any classification task\n",
    "- ✅ Fast training (only the classifier needs training, not the embedding model)\n",
    "- ✅ Good performance with less computational resources\n",
    "- ✅ Ability to reuse embeddings for multiple tasks\n",
    "\n",
    "### Predict Phase\n",
    "\n",
    "**Before running the code below, think about:**\n",
    "1. What is an embedding? What does \"768 dimensional dense vector space\" mean?\n",
    "2. Why would we use embeddings + a classifier instead of a task-specific model?\n",
    "3. What type of classifier do you think would work well on top of embeddings? Why?\n",
    "4. What are the advantages and disadvantages of this approach compared to Section A?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate**: \n",
    "- Why do we use `output[0]` and `output[2]`? What is `output[1]`?\n",
    "- What does `np.argmax` do? Why do we use it here?\n",
    "- What are the possible values in `y_pred`? How do they map to positive/negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433,
     "referenced_widgets": [
      "90e10c9366c4472daa76d4f5fdbf6082",
      "206a98c9a772416e9a3a82419d6e358a",
      "a6f8ec63bc2e446fad1bf21f88afe931",
      "0c7187f8a64a4599be547f5d2b6bd54b",
      "f68ad6800b2e420f8de4d919f9991c91",
      "2dea50d1f84944a7be5d1093252114fc",
      "dd75d91685d64d8e8b09df6d87bb6701",
      "ccd16dfd49e3414fa433fe47d1eb7308",
      "71e33f79b07942348551d7e018e43a30",
      "7027398ee4b448fca6dfe41d2b665e47",
      "ef0f98948019498cb5910a6ccc58effe",
      "8bd46413d6a24c0c9889de0c6420e804",
      "e4c71f26ab40424a9199e7b9768a6152",
      "460e1beb608448a08eaa2d76d0a342bf",
      "cae388785abd424db4510efd301a42e3",
      "3c91787fa03f4665842af41a62cf87e5",
      "8afe8f546dcd4c78b99f4cf049127d3b",
      "84f4f63280a94441986e05114ca41e51",
      "18942c10138a46c8919af87f11eb9147",
      "510cf2e6641847eabb09d953d68b8ca7",
      "f6d379d23f2342118320ae6340b0931d",
      "4b5d781bd47e47f791f2827677880951",
      "24a7c4c7d9764c328b37349a45bd0567",
      "f68cff8991194131b7abb7655788622c",
      "dd2036bdac984ee2881492de430a9789",
      "468f120e652045f2a10bcfa140327b86",
      "d0f8111991814cfba528b8800492ef80",
      "7e3abcd06dbf4e659b113058f83f4f51",
      "51edca045f78450ba8de8b79e1e60a33",
      "3def743ca3a14a479eb28a3288788672",
      "1bb153d1b18047fe98213131105dbec8",
      "b8290e6210034c18828a4cff14b99f9c",
      "2087fc53418e47aba5e2bb7a25708704",
      "62f47760176c47beab146ccfadb58de9",
      "b2b3c5bfac944b5e8c59492d6e0b4efc",
      "de6bde11246a4690bccaad745d325327",
      "9fd2fb9c34cc420985f0c650ccaf8946",
      "e24825ba0f3f476690c4257c250bd682",
      "1e7fd746397c496aa75803c2fc7eee4a",
      "5129ed295f604b5294e0cc51202f9e28",
      "4e65e64fd38141729dc9ec40ca9a325f",
      "2f65ebd9992544caab9a382c9dbfa89f",
      "444aafae9a8f46ce8aab3300ad2e3505",
      "7de1b03599f645f49536d12c1fb2d32c",
      "ef7f83d9388d417c92a1a77f66c0f488",
      "312462141a264c41b09f9832dfb9124a",
      "a78f9ffcbaa344b4bec4b3b30af4a124",
      "f1362eba3f3c4db0b10b83cbcc1d33f3",
      "fef9f0fe4bf04a41b7874b6d0e7ee2e2",
      "4c219b46e13144ff8716cd750815e6fc",
      "afddfad3234d497b9707e8f5515e5d6b",
      "326fbddb6c8c475db7565c0be35d4355",
      "d8f0161e33644d43978c78882dc19bdc",
      "1b7576dcee794c26b8fc5a56acc9c1b7",
      "47da96068fc344c488e7361e18ebb250",
      "1a88400680da4c09bd2e2c474a47c262",
      "e56c65f55e1243ce92417ae1d934e284",
      "74a23562af1c43f999353a592b130107",
      "6fdfa215a1ed4db8a3249431c3a46820",
      "6e81a1cbea374f73b58fd790dbfb78fd",
      "04eda3ef56a24f06ac242cdec14922b6",
      "6a6daecfce064ded8285b8acc03b1983",
      "fd18a5753982415e93b38cf74470f926",
      "b299e00db77d40bab37becbd11a4fe94",
      "d6bb987e5d5f437ea5599b0f742f4d54",
      "9bd7938c7f0047f7940ff66f017ce82d",
      "93dee9f8340745e3a5399c12433d2abf",
      "6a0b81236aa84c619d0bf265ee0bf472",
      "4f59e4ee08844f41b80b6bd2cf98135d",
      "dcc117d75e574da3bf0345ee36c18fec",
      "1fcc8f4a3dff476bbe2e359f3a975c2d",
      "d81b32f1d5d54655adee7f0b187e89b3",
      "d728bdce55bd4a72b5245e22373a14a4",
      "7f1a6b4b3be149238fa4eef1a954eefd",
      "11818a903b5a4d6f937ed64d9f959f70",
      "e11af452c5a94858977143c8b9470d91",
      "5ffc83971d234eeb9e53673ae93aa29b",
      "c87c13b512184b008e16a57ba4589cbd",
      "d152338a33fa42d2b60cc5386bd0f6bc",
      "ee4d2227443748d789eaad98e7ac27df",
      "61b0a9b24075449c90e67d18275019d5",
      "8c13acc4b7b145c083db65576edb335d",
      "56ed68b3e66e412bab8a2682dadad90c",
      "41e5a8b3841c47e991ee3ab3b4b9be0a",
      "869af7363dd14cfa8a5022ee95fa2e42",
      "890cbcf109794dc4835a3e5c6a3a1cb7",
      "7a808dce9af347b4b06b12fcee456b51",
      "1ca40a40491b48949f32875e08ed7dbe",
      "4e057e0b970647d9a800657505c51eed",
      "223f91c4bb6642dfa5fcccc6cfdf926d",
      "40caae4643d644bf892a17b8e5996c59",
      "4787e085720646dc91c0c80cf52387b5",
      "da446e9fd7f54421b876e047f20514ef",
      "83118ee8bbea4a7d92a316b24be76b70",
      "cd0adcb291f947868f5135c10abc3bf6",
      "85914ebe096643a1bfb2ba5ba47123e3",
      "8b14f69a4ca54aae9fef8c29d04e45bc",
      "a9a355f0f2634228a13ecc6ece169f07",
      "7e8894015ba54b6f9f28da55c96c0c32",
      "a0c8a705de694b39826618463f48020c",
      "120a9f380879441db8daddd087018faa",
      "69dc5b1149c64b55b269072bf8aca0ac",
      "0740923b39f9484e91e00a46a4b2cd44",
      "81f816455e08448eaaa9d655ce685428",
      "b6194c0a90c944159d48b15c7a9c694e",
      "16b6606982f243b7a538acac87a831d2",
      "72f7ab25f5cb478caaffa0f6eda978e8",
      "c35a554bab5843ba8362ba5edb1319ee",
      "432c162ee4b1403aacaae5820f79f0ee",
      "38dae46640b146e1b3d1310a3d7cf031",
      "077c2927fe4347a89a60424e101a77cd",
      "4507959185dc452f9402b5473f68569c",
      "54b55ab2fd24400aab6e41e44465a518",
      "289a95ae48f14ca3be28e6fa4823a896",
      "fe34e3ff89d44ca9a766e1e66a54c3a5",
      "f98ea240febb4636a6b5b4ebd8900ba6",
      "55be273779b34c4da05b766fee3b9bb4",
      "bdbf1669949044329171250002a12d5e",
      "e91355d03f3345ca91b4fbac6aa88339",
      "d462c1cf95254ac7b58967d88172bd97",
      "79c851c5052e44d5903610f8386a3400",
      "798913f849f041ccb3fbfcafd1ba4e80",
      "d604796627d9419d85a29f5f62b8afd7",
      "4833aec832404fc68cbc9c2cfbef41d2",
      "682c948c17f7467783165c31228b701b",
      "02bdae2308c14130a41eafac5935baab",
      "2616787d8d9e4f4d9129a433576ed2be",
      "76821dabd4c54a2e847207e95da261fd",
      "66502b2a95e049a2b885a9ad4292f31b",
      "73d2151fd5d74a8c9be157162bb8bbb8",
      "005cf3c4ad66478c872e0f75a1e56976",
      "8e218e004f7c4690863e2c7b6ab0958e",
      "3a69b4a92b854eaa92501351b20db5bb",
      "828d255f961b4a66af86f211b59374ae",
      "809d7e4cab174f5f943032b34c9e4c47",
      "a8c9dce33dca4e49ab5c361685b9c94b",
      "c36257029d3e49b3b72e062f03ac1e0e",
      "7f9c55029e59494aae1dcf5fbc52f5a0",
      "d4eb329feec1479aa09a8ffb735e26f4",
      "8a438d6d56964a08a3f8ff295e3a6660",
      "c421bf088bb043ad8d7c9e04749d3bfa",
      "a45e84b69d414ce2af3b1dde0f299311",
      "c83cee33a4ca41bab88f3dec50764eeb"
     ]
    },
    "id": "jODeYBKH8dw2",
    "outputId": "0fcc8ee1-d3fd-4f7b-d2c5-6fcfb10c5d0b"
   },
   "source": [
    "### Run Phase\n",
    "\n",
    "Let's load a Sentence Transformer model and convert our text to embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmRsHKzX8eqY",
    "outputId": "1a5af890-c806-4f78-a8f9-4e1445c0f7c3"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained Sentence Transformer model\n",
    "# This model converts text into 768-dimensional vectors\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Convert our text data to embeddings\n",
    "# Each review becomes a vector of 768 numbers\n",
    "train_embeddings = model.encode(data[\"train\"][\"text\"], show_progress_bar=True)\n",
    "test_embeddings = model.encode(data[\"test\"][\"text\"], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape of our embeddings to understand what we've created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "axLUc07Q8fmo",
    "outputId": "be6f6a34-3984-42f1-aba7-1e679141fee9"
   },
   "outputs": [],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tul0oL8_8gTY",
    "outputId": "ca088091-5c8f-4d6e-e93b-a51c1e76b68c"
   },
   "outputs": [],
   "source": [
    "# Predict previously unseen instances\n",
    "y_pred = clf.predict(test_embeddings)\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a simple classifier on top of these embeddings. We'll use Logistic Regression - a fast, interpretable classifier that works well with embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Phase\n",
    "\n",
    "**Exercise 1**: Examine the shape of the embeddings. What does each dimension represent?\n",
    "- The shape tells us: `(number of examples, embedding dimension)`\n",
    "- Each row is one review, each column is one dimension of meaning\n",
    "\n",
    "**Exercise 2**: Try encoding a single sentence and examine its embedding. What do you notice about the values?\n",
    "```python\n",
    "# Try this:\n",
    "single_embedding = model.encode(\"This is a test sentence\")\n",
    "print(f\"Shape: {single_embedding.shape}\")\n",
    "print(f\"Sample values: {single_embedding[0][:10]}\")\n",
    "print(f\"Min: {single_embedding.min()}, Max: {single_embedding.max()}\")\n",
    "```\n",
    "\n",
    "**Exercise 3**: Compare embeddings of similar vs different sentences. What patterns do you see?\n",
    "```python\n",
    "# Try this:\n",
    "similar1 = model.encode(\"I love this movie\")\n",
    "similar2 = model.encode(\"This film is amazing\")\n",
    "different = model.encode(\"The weather is nice today\")\n",
    "\n",
    "# Calculate cosine similarity (we'll learn about this in Section C)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(\"Similar sentences:\", cosine_similarity([similar1], [similar2])[0][0])\n",
    "print(\"Different sentences:\", cosine_similarity([similar1], [different])[0][0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate**: \n",
    "- Why did we choose Logistic Regression? What other classifiers could we use?\n",
    "- How long did training take compared to using a task-specific model?\n",
    "- What are the advantages of this approach?\n",
    "\n",
    "Now let's evaluate our classifier on the test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Phase\n",
    "\n",
    "**Exercise 1**: Try a different task-specific model. Replace `\"cardiffnlp/twitter-roberta-base-sentiment-latest\"` with `\"distilbert-base-uncased-finetuned-sst-2-english\"`. How does the performance compare?\n",
    "\n",
    "**Exercise 2**: Modify the code to handle cases where the model might return scores in a different order. Make the code more robust by finding the label names dynamically.\n",
    "\n",
    "**Exercise 3**: Add code to show some example predictions (both correct and incorrect) to understand where the model struggles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: By training a classifier on top of our embeddings, we managed to get an F1 score of 0.85! This demonstrates the possibilities of training a lightweight classifier while keeping the underlying embedding model frozen.\n",
    "\n",
    "### Modify Phase\n",
    "\n",
    "**Exercise 1**: Try different classifiers from scikit-learn (e.g., `RandomForestClassifier`, `SVM`, `NaiveBayes`). Compare their performance and training time.\n",
    "\n",
    "**Exercise 2**: Experiment with different embedding models. Try `sentence-transformers/all-MiniLM-L6-v2` (smaller, faster) or `sentence-transformers/all-mpnet-base-v2` (current). How do they compare?\n",
    "\n",
    "**Exercise 3**: Add regularization to the Logistic Regression. Try different `C` values and see how it affects performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Nd0V14_8jTH"
   },
   "source": [
    "By training a classifier on top of our embeddings, we managed to get an F1 score of 0.85! This demonstrates the possibilities of training a lightweight classifier while keeping the underlying embedding model frozen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate**: \n",
    "- Why did we choose Logistic Regression? What other classifiers could we use?\n",
    "- How long did training take compared to using a task-specific model?\n",
    "- What are the advantages of this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtRq0i-p8hXM"
   },
   "source": [
    "> TIP: In this example, we used sentence-transformers to extract our embeddings, which benefits from a GPU to speed up inference. However, we can remove this GPU dependency by using an external API to create the embeddings. Popular choices for generating embeddings are Cohere’s and OpenAI’s offerings. As a result, this would allow the pipeline to run entirely on the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfVc7PNM8kc3"
   },
   "source": [
    "## C. Using just the Embedding Model (headless) + Cosine Similarity\n",
    "\n",
    "**What If We Do Not Have Labeled Data?**\n",
    "\n",
    "Getting labeled data is a resource-intensive task that can require significant human labor. Moreover, is it actually worthwhile to collect these labels?\n",
    "\n",
    "To perform **zero-shot classification** with embeddings, there is a neat trick that we can use. We can describe our labels based on what they should represent. For example, a negative label for movie reviews can be described as “This is a negative movie review.” By describing and embedding the labels and documents, we have data that we can work with. This process, as illustrated in Figure 4-14, allows us to generate our own target labels without the need to actually have any labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNVJ7ZtH8lc5"
   },
   "source": [
    "<img src=\"https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098150952/files/assets/holl_0414.png\" alt=\"Figure 4-14. To embed the labels, we first need to give them a description, such as “a negative movie review.” This can then be embedded through sentence-transformers.\">\n",
    "\n",
    "Figure 4-14. To embed the labels, we first need to give them a description, such as “a negative movie review.” This can then be embedded through sentence-transformers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Phase\n",
    "\n",
    "**Exercise 1**: Examine the shape of the embeddings. What does each dimension represent?\n",
    "\n",
    "**Exercise 2**: Try encoding a single sentence and examine its embedding. What do you notice about the values?\n",
    "```python\n",
    "# Try this:\n",
    "single_embedding = model.encode(\"This is a test sentence\")\n",
    "print(f\"Shape: {single_embedding.shape}\")\n",
    "print(f\"Sample values: {single_embedding[0][:10]}\")\n",
    "```\n",
    "\n",
    "**Exercise 3**: Compare embeddings of similar vs different sentences. What patterns do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAIYOeci8ovh"
   },
   "outputs": [],
   "source": [
    "# Create embeddings for our labels\n",
    "label_embeddings = model.encode([\n",
    "    \"A negative review\",\n",
    "    \"A positive review\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqpfbwdj8ppJ"
   },
   "source": [
    "<img src=\"https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098150952/files/assets/holl_0415.png\">\n",
    "\n",
    "Figure 4-15. The cosine similarity is the angle between two vectors or embeddings. In this example, we calculate the similarity between a document and the two possible labels, positive and negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P74dTMFP8quV"
   },
   "source": [
    "<img src=\"https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098150952/files/assets/holl_0416.png\" />\n",
    "\n",
    "Figure 4-16. After embedding the label descriptions and the documents, we can use cosine similarity for each label document pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwgfyBV-8rcl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Find the best matching label for each document\n",
    "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
    "y_pred = np.argmax(sim_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate**: \n",
    "- Why did we choose Logistic Regression? What other classifiers could we use?\n",
    "- How long did training take compared to using a task-specific model?\n",
    "- What are the advantages of this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4WjuMuh8sP7"
   },
   "source": [
    "And that is it! We only needed to come up with names for our labels to perform our classification tasks. Let’s see how well this method works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2btEd8Ab8s9a",
    "outputId": "9167964c-91e3-430a-dca2-d4df063cde88"
   },
   "outputs": [],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Phase\n",
    "\n",
    "**Exercise 1**: Try different classifiers from scikit-learn (e.g., `RandomForestClassifier`, `SVM`, `NaiveBayes`). Compare their performance and training time.\n",
    "\n",
    "**Exercise 2**: Experiment with different embedding models. Try `sentence-transformers/all-MiniLM-L6-v2` (smaller, faster) or `sentence-transformers/all-mpnet-base-v2` (current). How do they compare?\n",
    "\n",
    "**Exercise 3**: Add regularization to the Logistic Regression. Try different `C` values and see how it affects performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-FGaJsO8t9f"
   },
   "source": [
    "#### Improve our label emeddings\n",
    "\n",
    "Let's try improving our label embeddings by:\n",
    "1. making it more polar by having the word \"very\" and\n",
    "2. being more specific by adding the word \"movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpOBewI78uw7"
   },
   "outputs": [],
   "source": [
    "# Create embeddings for our labels\n",
    "label_embeddings = model.encode([\n",
    "    \"A very negative movie review\",\n",
    "    \"A very positive movie review\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlkWpfTe8viI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Find the best matching label for each document\n",
    "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
    "y_pred = np.argmax(sim_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLuxjJJU8wXN",
    "outputId": "34718d39-5fbd-49b9-d879-f7aca3cdd572"
   },
   "outputs": [],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFS6d0FI8xTd"
   },
   "source": [
    "Do you notice the performance increase?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBR3Idfv8x4j"
   },
   "source": [
    "> [The author](https://jalammar.github.io/) notes that using NLI-based [zero-shot classification](https://huggingface.co/tasks/zero-shot-classification) **is better than using emedding models**. However, this was done to illustrate the **versatility of emedding models**. We will look at **Natural Language Inference (NLI)** in the next notebook Inshallah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Phase\n",
    "\n",
    "**Exercise 1**: What is the shape of `label_embeddings`? Why does it have this shape?\n",
    "\n",
    "**Exercise 2**: Calculate the cosine similarity between the two label embeddings. What does this tell you about how similar \"negative review\" and \"positive review\" are in the embedding space?\n",
    "\n",
    "**Exercise 3**: Try different label descriptions. How do they affect the embeddings?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "000d701befcd408da26ef5e393a19522": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0041e817ec674ab295ce95d19538f6f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_abd46b77751747439f0449ee15205cf9",
       "IPY_MODEL_0104a65dc4c9432eb96256f1bbe30a5b",
       "IPY_MODEL_d6e73601c5f54aee80f96e3b2c973b21"
=======
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Phase\n",
        "\n",
        "**Before running the code below, think about:**\n",
        "1. What do you think `pipeline` does? What are its advantages?\n",
        "2. What does `return_all_scores=True` mean?\n",
        "3. Why might we specify `device=\"cuda\"`?\n",
        "4. What will the output format look like?\n",
        "\n",
        "### Run Phase\n",
        "\n",
        "Now let's create our pipeline. We'll use a specific model that's been trained on Twitter data for sentiment analysis:"
>>>>>>> e647be3470a22fb40a797cef770c6164b0cae57c
      ],
      "metadata": {
        "id": "pHeP9TgSxr7g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOxQqq6UxkWL"
      },
      "source": [
        "Now let's create our pipeline. We'll use a specific model that's been trained on Twitter data for sentiment analysis:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Path to our Hugging Face model\n",
        "# This model was trained on Twitter data for sentiment analysis\n",
        "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "# Create a pipeline for sentiment analysis\n",
        "# - model: specifies which pre-trained model to use\n",
        "# - tokenizer: converts text to numbers (usually same as model name)\n",
        "# - return_all_scores: returns scores for all classes, not just the top one\n",
        "# - device: \"cuda\" for GPU (faster), \"cpu\" for CPU (works everywhere)\n",
        "pipe = pipeline(\n",
        "    \"sentiment-analysis\",  # The task we want to perform\n",
        "    model=model_path,\n",
        "    tokenizer=model_path,\n",
        "    return_all_scores=True,\n",
        "    device=\"cuda\"\n",
        ")"
      ],
      "metadata": {
        "id": "IErZX4AYxwPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfe13E67xkWM"
      },
      "source": [
        "Now let's run inference on the entire test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM9cQ28M8VlA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "\n",
        "# Run inference\n",
        "y_pred = []\n",
        "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"text\")), total=len(data[\"test\"])):\n",
        "    negative_score = output[0][\"score\"]\n",
        "    positive_score = output[2][\"score\"]\n",
        "    assignment = np.argmax([negative_score, positive_score])\n",
        "    y_pred.append(assignment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AC-ezxvxkWM"
      },
      "source": [
        "**Investigate**:\n",
        "- Why do we use `output[0]` and `output[2]`? What is `output[1]`?\n",
        "- What does `np.argmax` do? Why do we use it here?\n",
        "- What are the possible values in `y_pred`? How do they map to positive/negative?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i_wnkkc8Wlm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_performance(y_true, y_pred):\n",
        "    \"\"\"Create and print the classification report\"\"\"\n",
        "    performance = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
        "    )\n",
        "    print(performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFnwiq968Xi_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_performance(y_true, y_pred):\n",
        "    \"\"\"Create and print the classification report\"\"\"\n",
        "    performance = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
        "    )\n",
        "    print(performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9bhAQ-mxkWN"
      },
      "source": [
        "Now let's evaluate the performance:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "eQKCPRj8x2iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vw7uvdhxkWN"
      },
      "source": [
        "**Note**: To improve the performance of our selected model, we could do a few different things including selecting a model trained on our domain data, movie reviews in this case, like DistilBERT base uncased finetuned SST-2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRIve2Nj8bDD"
      },
      "source": [
        "---\n",
        "\n",
        "## Section B: Using an Embedding Model + Classifier Head\n",
        "\n",
        "### Introduction to Sentence Transformers\n",
        "\n",
        "However, what if we cannot find a model that was pretrained for this specific task? Do we need to fine-tune a representation model ourselves? The answer is no!\n",
        "\n",
        "There might be times when you want to fine-tune the model yourself if you have sufficient computing available. However, not everyone has access to extensive computing. This is where general-purpose embedding models come in.\n",
        "\n",
        "#### What is Sentence Transformers?\n",
        "\n",
        "**Sentence Transformers** is a Python library built on top of Hugging Face Transformers that specializes in creating **embeddings** - numerical representations of text that capture semantic meaning.\n",
        "\n",
        "The model `sentence-transformers/all-mpnet-base-v2` we'll use:\n",
        "- Maps sentences & paragraphs to a **768-dimensional** dense vector space\n",
        "- Each dimension captures some aspect of the text's meaning\n",
        "- Can be used for tasks like clustering, semantic search, or (as we'll see) classification\n",
        "\n",
        "#### The Strategy: Embeddings + Classifier\n",
        "\n",
        "Instead of using a task-specific model, we'll:\n",
        "1. **Convert text to embeddings** using Sentence Transformers (frozen, no training needed)\n",
        "2. **Train a simple classifier** (like Logistic Regression) on top of these embeddings\n",
        "\n",
        "This approach gives us:\n",
        "- ✅ Flexibility to adapt to any classification task\n",
        "- ✅ Fast training (only the classifier needs training, not the embedding model)\n",
        "- ✅ Good performance with less computational resources\n",
        "- ✅ Ability to reuse embeddings for multiple tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Phase\n",
        "\n",
        "Let's load a Sentence Transformer model and convert our text to embeddings:"
      ],
      "metadata": {
        "id": "KMgbaEukysM5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmRsHKzX8eqY"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load a pre-trained Sentence Transformer model\n",
        "# This model converts text into 768-dimensional vectors\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dboe-V18xkWO"
      },
      "source": [
        "### Investigate Phase\n",
        "\n",
        "**Exercise**: Try encoding a single sentence and examine its embedding. What do you notice about the values?\n",
        "```python\n",
        "# Try this:\n",
        "single_embedding = model.encode(\"This is a test sentence\")\n",
        "print(f\"Shape: {single_embedding.shape}\")\n",
        "print(f\"Sample values: {single_embedding[0][:10]}\")\n",
        "print(f\"Min: {single_embedding.min()}, Max: {single_embedding.max()}\")\n",
        "```\n",
        "\n",
        "**Exercise 3**: Compare embeddings of similar vs different sentences. What patterns do you see?\n",
        "```python\n",
        "# Try this:\n",
        "similar1 = model.encode(\"I love this movie\")\n",
        "similar2 = model.encode(\"This film is amazing\")\n",
        "different = model.encode(\"The weather is nice today\")\n",
        "\n",
        "# Calculate cosine similarity (we'll learn about this in Section C)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print(\"Similar sentences:\", cosine_similarity([similar1], [similar2])[0][0])\n",
        "print(\"Different sentences:\", cosine_similarity([similar1], [different])[0][0])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert our text data to embeddings\n",
        "# Each review becomes a vector of 768 numbers\n",
        "train_embeddings = model.encode(data[\"train\"][\"text\"], show_progress_bar=True)\n",
        "test_embeddings = model.encode(data[\"test\"][\"text\"], show_progress_bar=True)"
      ],
      "metadata": {
        "id": "frsQOD2N1AJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0ebTOSsxkWO"
      },
      "source": [
        "Let's check the shape of our embeddings to understand what we've created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axLUc07Q8fmo"
      },
      "outputs": [],
      "source": [
        "train_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llmx6TNWxkWO"
      },
      "source": [
        "Now let's train a simple classifier on top of these embeddings. We'll use Logistic Regression - a fast, interpretable classifier that works well with embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train a classifier on embeddings\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(train_embeddings, data[\"train\"][\"label\"])"
      ],
      "metadata": {
        "id": "elw0ZN2H0xhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now let's evaluate our classifier on the test set:"
      ],
      "metadata": {
        "id": "vIbQ05hN1RiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate\n",
        "y_pred = clf.predict(test_embeddings)\n",
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "oZUlmCEt1Sf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOb-gzR3xkWO"
      },
      "source": [
        "**Investigate**:\n",
        "\n",
        "- What are the advantages of this approach?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkQFtT_kxkWO"
      },
      "source": [
        "**Result**: By training a classifier on top of our embeddings, we managed to get an F1 score of 0.85! This demonstrates the possibilities of training a lightweight classifier while keeping the underlying embedding model frozen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfVc7PNM8kc3"
      },
      "source": [
        "## C. Using just the Embedding Model (headless) + Cosine Similarity\n",
        "\n",
        "**What If We Do Not Have Labeled Data?**\n",
        "\n",
        "Getting labeled data is a resource-intensive task that can require significant human labor. Moreover, is it actually worthwhile to collect these labels?\n",
        "\n",
        "To perform **zero-shot classification** with embeddings, there is a neat trick that we can use. We can describe our labels based on what they should represent. For example, a negative label for movie reviews can be described as “This is a negative movie review.” By describing and embedding the labels and documents, we have data that we can work with. This process, as illustrated in Figure 4-14, allows us to generate our own target labels without the need to actually have any labeled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNVJ7ZtH8lc5"
      },
      "source": [
        "<img src=\"https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098150952/files/assets/holl_0414.png\" alt=\"Figure 4-14. To embed the labels, we first need to give them a description, such as “a negative movie review.” This can then be embedded through sentence-transformers.\">\n",
        "\n",
        "Figure 4-14. To embed the labels, we first need to give them a description, such as “a negative movie review.” This can then be embedded through sentence-transformers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAIYOeci8ovh"
      },
      "outputs": [],
      "source": [
        "# Create embeddings for our labels\n",
        "label_embeddings = model.encode([\n",
        "    \"A negative review\",\n",
        "    \"A positive review\"\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqpfbwdj8ppJ"
      },
      "source": [
        "<img src=\"https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098150952/files/assets/holl_0415.png\">\n",
        "\n",
        "Figure 4-15. The cosine similarity is the angle between two vectors or embeddings. In this example, we calculate the similarity between a document and the two possible labels, positive and negative.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P74dTMFP8quV"
      },
      "source": [
        "<img src=\"https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098150952/files/assets/holl_0416.png\" />\n",
        "\n",
        "Figure 4-16. After embedding the label descriptions and the documents, we can use cosine similarity for each label document pair.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwgfyBV-8rcl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Find the best matching label for each document\n",
        "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
        "y_pred = np.argmax(sim_matrix, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4WjuMuh8sP7"
      },
      "source": [
        "And that is it! We only needed to come up with names for our labels to perform our classification tasks. Let’s see how well this method works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2btEd8Ab8s9a"
      },
      "outputs": [],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-FGaJsO8t9f"
      },
      "source": [
        "#### Improve our label emeddings\n",
        "\n",
        "Let's try improving our label embeddings by:\n",
        "1. making it more polar by having the word **\"very\"** and\n",
        "2. being more specific by adding the word **\"movie\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpOBewI78uw7"
      },
      "outputs": [],
      "source": [
        "# Create embeddings for our labels\n",
        "label_embeddings = model.encode([\n",
        "    \"A very negative movie review\",\n",
        "    \"A very positive movie review\"\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlkWpfTe8viI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Find the best matching label for each document\n",
        "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
        "y_pred = np.argmax(sim_matrix, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLuxjJJU8wXN"
      },
      "outputs": [],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFS6d0FI8xTd"
      },
      "source": [
        "Do you notice the performance increase?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBR3Idfv8x4j"
      },
      "source": [
        "> The author [(Jay Alammar)](https://jalammar.github.io/) notes that using NLI-based [zero-shot classification](https://huggingface.co/tasks/zero-shot-classification) **is better than using emedding models**. However, this was done to illustrate the **versatility of emedding models**. We will look at **Natural Language Inference (NLI)** in the next notebook Inshallah."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}